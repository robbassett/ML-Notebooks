{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Deep Q Learning </center>\n",
    "\n",
    "In the previous notebook we looked at the basics of Q-learning employed in environments with discrete action and observation spaces. For real world problems this is not necessarily the case, thus simply constructing a Q-table and updating it with the Bellman Equation is not viable. In this notebook we are going to explore deep Q-learning in environments with continuous observation spaces (the action space is still discrete). \n",
    "\n",
    "## <center> OpenAI Gym's CartPole Environment </center>\n",
    "\n",
    "<img src=\"openaigym.svg\" width=200 />\n",
    "\n",
    "We'll again be using environments from OpenAI Gym, but this time from the \"classic control\" set. In particular we will create a deep Q-learning agent to perform in the CartPole environment. This is a 2D environment in which a pole is balanced atop a movable cart, and the goal is to prevent the pole from falling over. There are two ways to fail: first if the pole leans over beyond an angle of 15 degrees (from the vertical) or the cart moves more than 2.4 \"units\" from the center of the environment. At each timestep, the agent must choose whether or move the cart either left or right or to do nothing; an action space of size 3. The maximum number of steps is fixed at 500, thus, a successful CartPole agent should be able to complete 500 steps without triggering one of these failure conditions. Lets have a first look at the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03875146  0.03335326 -0.01446357 -0.04827759]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "plt.imshow(env.render(mode='rgb_array'))\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the pole is the brown thing and the cart is the black thing which moves along the track represented by the grey line. We also see that the state of the environment is represented by four continuous values that represent the cart position, cart velocity, pole angle, and pole angular velocity. Our goal will be to create an agent that can take in these four values as an input and determine the optimal action to keep the pole upright. \n",
    "\n",
    "For this task, we are going to employ an artificial neural network (NN) using the keras package. First let's simply try creating a simple linear NN classifier with a single hidden layer of 64 neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# We'll create a Neural Network as a class that will be a part of our agent class later\n",
    "class LinearClassifier():\n",
    "    \n",
    "    # The arguments required will be the learning rate, the number\n",
    "    # of actions (3 possible for CartPole), and the dimensions of\n",
    "    # the observation space (4 variables). We also include a save\n",
    "    # directory and a name so we can save the final weights of our\n",
    "    # model for verification at the end.\n",
    "    def __init__(self,lrate,n_action,dimensions,save_dir='tmp/',name='CartBoy'):\n",
    "        self.save_file = f'{save_dir}{name}.h5'\n",
    "        \n",
    "        # Here we are going to define our optimizer and our loss\n",
    "        # functions. These determine exactly how the weights of\n",
    "        # our model get updated at each learning step. We are going\n",
    "        # to use the Adam optimizer and a mean squared error loss\n",
    "        # function, which are fairly standard in this type of problem.\n",
    "        # These will be called by our agent's \"learn\" function later.\n",
    "        self.optimizer = keras.optimizers.Adam(learning_rate=lrate)\n",
    "        self.loss = keras.losses.MeanSquaredError()\n",
    "        \n",
    "        # Now we define the layers of our neural network. \n",
    "        \n",
    "        # In keras\n",
    "        # we first need to define an input layer, which is given\n",
    "        # a shape equivalent to the input dimensions. \n",
    "        Input = layers.Input(shape=dimensions)\n",
    "    \n",
    "        # Layer1 is the\n",
    "        # hidden layer which contains 64 neurons, and uses an \"relu\"\n",
    "        # activation function. Basically, each neuron will consist\n",
    "        # of 4 values that are multiplied by the input values, summed,\n",
    "        # then passed to the activation function to return a single number.\n",
    "        # Thus, we input 4 numbers, and Layer1 returns 64 numbers \n",
    "        # corresponding to each of the 64 neurons. Also, notice that\n",
    "        # we specify that the Input layer is taken as the argument\n",
    "        # of Layer1.\n",
    "        Layer1 = layers.Dense(64, activation='relu')(Input)\n",
    "        \n",
    "        # Finally, we have the output layer, which will take the 64\n",
    "        # values output by Layer1 and output a single value for each\n",
    "        # of our 3 possible actions. Later, the agent will determine\n",
    "        # the optimal action by passing the observations through this\n",
    "        # neural network and choosing the action highest value in the\n",
    "        # output layer. Note that our output layer does not employ\n",
    "        # an activation function.\n",
    "        Output = layers.Dense(n_action)(Layer1)\n",
    "        \n",
    "        # Now we put it all together\n",
    "        self.model = keras.Model(inputs=Input,outputs=Output)\n",
    "        \n",
    "    # Finally we include functions for saving and loading the model weights\n",
    "    def save_model(self):\n",
    "        self.model.save(self.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
